{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac773e34",
   "metadata": {
    "papermill": {
     "duration": 0.031076,
     "end_time": "2022-06-20T07:20:51.204762",
     "exception": false,
     "start_time": "2022-06-20T07:20:51.173686",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **IMPORTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5a5a3a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T07:20:51.280250Z",
     "iopub.status.busy": "2022-06-20T07:20:51.279349Z",
     "iopub.status.idle": "2022-06-20T07:21:03.625666Z",
     "shell.execute_reply": "2022-06-20T07:21:03.626289Z",
     "shell.execute_reply.started": "2022-06-20T07:19:09.873353Z"
    },
    "papermill": {
     "duration": 12.392602,
     "end_time": "2022-06-20T07:21:03.626573",
     "exception": false,
     "start_time": "2022-06-20T07:20:51.233971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lpips\r\n",
      "  Downloading lpips-0.1.4-py3-none-any.whl (53 kB)\r\n",
      "     |████████████████████████████████| 53 kB 437 kB/s            \r\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from lpips) (1.7.2)\r\n",
      "Requirement already satisfied: tqdm>=4.28.1 in /opt/conda/lib/python3.7/site-packages (from lpips) (4.62.3)\r\n",
      "Requirement already satisfied: torchvision>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from lpips) (0.10.1)\r\n",
      "Requirement already satisfied: torch>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from lpips) (1.9.1)\r\n",
      "Requirement already satisfied: numpy>=1.14.3 in /opt/conda/lib/python3.7/site-packages (from lpips) (1.19.5)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=0.4.0->lpips) (3.10.0.2)\r\n",
      "Requirement already satisfied: pillow>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision>=0.2.1->lpips) (8.2.0)\r\n",
      "Installing collected packages: lpips\r\n",
      "Successfully installed lpips-0.1.4\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from numpy import *\n",
    "from numpy.linalg import *\n",
    "from scipy.special import factorial\n",
    "from functools import reduce\n",
    "import random\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import gzip\n",
    "import cv2\n",
    "import math\n",
    "import os\n",
    "from PIL import Image\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.transform import resize\n",
    "import argparse\n",
    "!pip install lpips\n",
    "import codecs\n",
    "import lpips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26358b27",
   "metadata": {
    "papermill": {
     "duration": 0.030911,
     "end_time": "2022-06-20T07:21:03.689792",
     "exception": false,
     "start_time": "2022-06-20T07:21:03.658881",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **UTILITY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fce59235",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T07:21:03.757043Z",
     "iopub.status.busy": "2022-06-20T07:21:03.756185Z",
     "iopub.status.idle": "2022-06-20T07:21:03.758693Z",
     "shell.execute_reply": "2022-06-20T07:21:03.758170Z",
     "shell.execute_reply.started": "2022-06-20T07:19:17.267521Z"
    },
    "papermill": {
     "duration": 0.038433,
     "end_time": "2022-06-20T07:21:03.758814",
     "exception": false,
     "start_time": "2022-06-20T07:21:03.720381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "437550a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T07:21:03.824283Z",
     "iopub.status.busy": "2022-06-20T07:21:03.823474Z",
     "iopub.status.idle": "2022-06-20T07:21:03.833455Z",
     "shell.execute_reply": "2022-06-20T07:21:03.833010Z",
     "shell.execute_reply.started": "2022-06-20T07:19:17.281396Z"
    },
    "papermill": {
     "duration": 0.043971,
     "end_time": "2022-06-20T07:21:03.833566",
     "exception": false,
     "start_time": "2022-06-20T07:21:03.789595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def schedule_sampling(eta, itr, channel, batch_size):\n",
    "    zeros = np.zeros((batch_size, args.total_length - args.input_length - 1, args.img_height, args.img_width, channel))\n",
    "    if not args.scheduled_sampling:\n",
    "        return 0.0, zeros\n",
    "\n",
    "    if itr < args.sampling_stop_iter:\n",
    "        eta -= args.sampling_changing_rate\n",
    "    else:\n",
    "        eta = 0.0\n",
    "        \n",
    "    if(configs.verbose or itr % 100 == 0):\n",
    "        print('ETA: ', eta)\n",
    "    random_flip = np.random.random_sample((batch_size, args.total_length - args.input_length - 1))\n",
    "    true_token = (random_flip < eta) # replace 0.5 with eta\n",
    "    ones = np.ones((args.img_height, args.img_width, channel))\n",
    "    zeros = np.zeros((args.img_height, args.img_width, channel))\n",
    "    \n",
    "    mask = []\n",
    "    for i in range(batch_size):\n",
    "        for j in range(args.total_length - args.input_length - 1):\n",
    "            if true_token[i, j]:\n",
    "                mask.append(ones)\n",
    "            else:\n",
    "                mask.append(zeros)\n",
    "                \n",
    "    mask = np.array(mask)\n",
    "    mask = np.reshape(mask, (batch_size, args.total_length - args.input_length - 1, args.img_height, args.img_width, channel))\n",
    "    return eta, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ff53dfc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T07:21:03.898586Z",
     "iopub.status.busy": "2022-06-20T07:21:03.897772Z",
     "iopub.status.idle": "2022-06-20T07:21:03.903805Z",
     "shell.execute_reply": "2022-06-20T07:21:03.903360Z",
     "shell.execute_reply.started": "2022-06-20T07:19:17.309205Z"
    },
    "papermill": {
     "duration": 0.03971,
     "end_time": "2022-06-20T07:21:03.903923",
     "exception": false,
     "start_time": "2022-06-20T07:21:03.864213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Resize2(object):\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        imgs_out = np.zeros((\n",
    "            sample.shape[0], 640, 480, sample.shape[3]))\n",
    "        for i in range(sample.shape[0]):\n",
    "            imgs_out[i,:,:,:] = resize(sample[i,:,:,:], imgs_out.shape[1:])\n",
    "        return imgs_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "100d93bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T07:21:03.995512Z",
     "iopub.status.busy": "2022-06-20T07:21:03.990576Z",
     "iopub.status.idle": "2022-06-20T07:21:03.997886Z",
     "shell.execute_reply": "2022-06-20T07:21:03.997465Z",
     "shell.execute_reply.started": "2022-06-20T07:19:17.327431Z"
    },
    "papermill": {
     "duration": 0.06231,
     "end_time": "2022-06-20T07:21:03.998002",
     "exception": false,
     "start_time": "2022-06-20T07:21:03.935692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluation_proper(model, test_loader, configs, out_len=10):\n",
    "    print('Evaluating...')\n",
    "    \n",
    "    loss_fn = lpips.LPIPS(net='alex', spatial=True).to(configs.device)\n",
    "    mse_list = np.empty((len(test_loader), out_len))\n",
    "    mae_list = np.empty((len(test_loader), out_len))\n",
    "    ssim_list = np.empty((len(test_loader), out_len))\n",
    "    psnr_list = np.empty((len(test_loader), out_len))\n",
    "    lpips_list = np.empty((len(test_loader), out_len))\n",
    "    \n",
    "    total_mse = 0\n",
    "    total_mae = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        #model.eval()\n",
    "        for i, data in tqdm(enumerate(test_loader, 0), total=len(test_loader)):\n",
    "#             if i == 1000:\n",
    "#                 break\n",
    "            batch_size = data.shape[0]\n",
    "            real_input_flag = np.zeros(\n",
    "                (batch_size,\n",
    "                 configs.total_length - configs.input_length - 1,\n",
    "                 configs.img_height // configs.patch_size,\n",
    "                 configs.img_width // configs.patch_size,\n",
    "                 configs.patch_size ** 2 * configs.img_channel))\n",
    "\n",
    "            img_gen = model.test(data, real_input_flag)\n",
    "            img_gen = img_gen.transpose(0, 1, 3, 4, 2)  # * 0.5 + 0.5\n",
    "            test_ims = data.detach().cpu().numpy().transpose(0, 1, 3, 4, 2)  # * 0.5 + 0.5\n",
    "            output_length = configs.total_length - configs.input_length\n",
    "            output_length = min(output_length, configs.total_length - 1)\n",
    "            target = data[:, configs.input_length:, :].detach().cpu().numpy().transpose(0, 1, 3, 4, 2)\n",
    "            predictions = img_gen[:, -output_length:, :]\n",
    "            \n",
    "            p_min = predictions.min()\n",
    "            p_max = predictions.max()\n",
    "            n_min = 0\n",
    "            n_max = 1\n",
    "            \n",
    "            #predictions = (predictions - p_min)/(p_max - p_min)*(n_max - n_min) + n_min\n",
    "            predictions[predictions < 0.10] = 0\n",
    "            predictions[predictions > 0.99] = 1\n",
    "            \n",
    "            if (i+1) % 50 == 0:\n",
    "                print(target[0, 1, 40:42, 40:42, 0])\n",
    "                print(predictions[0, 1, 40:42, 40:42, 0])\n",
    "                fig, ax = plt.subplots(2, out_len, figsize=(25, 7))\n",
    "                for i in range(2):\n",
    "                    for j in range(out_len):\n",
    "                        if i == 0:\n",
    "                            ax[i][j].imshow(target[0][j])\n",
    "                            ax[i][j].set_title('V Ground Truth')\n",
    "                        if i == 1:\n",
    "                            ax[i][j].imshow(predictions[0][j])\n",
    "                            ax[i][j].set_title('V Generated')\n",
    "                        ax[i][j].axis('off')\n",
    "                plt.show()\n",
    "            \n",
    "            mse_batch = np.mean((predictions-target)**2 , axis=(0,1,4)).sum()\n",
    "            mae_batch = np.mean(np.abs(predictions-target),  axis=(0,1,4)).sum() \n",
    "            total_mse += mse_batch\n",
    "            total_mae += mae_batch\n",
    "            \n",
    "            for j in range(out_len):\n",
    "                mse_list[i][j] = np.square(predictions[:,j,:,:,:] - target[:,j,:,:,:]).mean()\n",
    "                mae_list[i][j] = np.abs(predictions[:,j,:,:,:] - target[:,j,:,:,:]).mean()\n",
    "                ssim_list[i][j] = ssim(target[0,j,:,:,:], predictions[0,j,:,:,:], multichannel=True)\n",
    "                psnr_list[i][j] = 20 * np.log10(1 / sqrt(mse_list[i][j]))\n",
    "                t1 = torch.from_numpy((predictions[:,j,:,:,:] - 0.5) / 0.5).to(configs.device).permute((0, 3, 1, 2))\n",
    "                t2 = torch.from_numpy((target[:,j,:,:,:] - 0.5) / 0.5).to(configs.device).permute((0, 3, 1, 2))\n",
    "                d = loss_fn.forward(t1, t2)\n",
    "                lpips_list[i][j] = d.mean().detach().cpu().numpy() * 100\n",
    "                    \n",
    "        #model.train()\n",
    "        \n",
    "    avg_mse_frame = mse_list.mean(axis=0)\n",
    "    avg_mae_frame = mae_list.mean(axis=0)\n",
    "    avg_ssim_frame = ssim_list.mean(axis=0)\n",
    "    avg_psnr_frame = psnr_list.mean(axis=0)\n",
    "    avg_lpips_frame = lpips_list.mean(axis=0)\n",
    "\n",
    "    avg_mse = mse_list.mean()\n",
    "    avg_mae = mae_list.mean()\n",
    "    avg_ssim = ssim_list.mean()\n",
    "    avg_psnr = psnr_list.mean()\n",
    "    avg_lpips = lpips_list.mean()\n",
    "\n",
    "    print('Eval MSE: ', total_mse/len(test_loader))\n",
    "    print('Eval MAE: ', total_mae/len(test_loader))\n",
    "    \n",
    "    print(f'Avg-MSE: {avg_mse}\\nMSE/Frame: {avg_mse_frame}')\n",
    "    print(f'Avg-MAE: {avg_mae}\\nMAE/Frame: {avg_mae_frame}')\n",
    "    print(f'Avg-SSIM: {avg_ssim}\\nSSIM/Frame: {avg_ssim_frame}')\n",
    "    print(f'Avg-PSNR: {avg_psnr}\\nPSNR/Frame: {avg_psnr_frame}')\n",
    "    print(f'Avg-LPIPS: {avg_lpips}\\nLPIPS/Frame: {avg_lpips_frame}')\n",
    "    \n",
    "    return avg_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777142d9",
   "metadata": {
    "papermill": {
     "duration": 0.029765,
     "end_time": "2022-06-20T07:21:04.058149",
     "exception": false,
     "start_time": "2022-06-20T07:21:04.028384",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **DATA LOADER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae3e5c26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T07:21:04.130390Z",
     "iopub.status.busy": "2022-06-20T07:21:04.129474Z",
     "iopub.status.idle": "2022-06-20T07:21:04.131974Z",
     "shell.execute_reply": "2022-06-20T07:21:04.131569Z",
     "shell.execute_reply.started": "2022-06-20T07:19:17.377340Z"
    },
    "papermill": {
     "duration": 0.042623,
     "end_time": "2022-06-20T07:21:04.132092",
     "exception": false,
     "start_time": "2022-06-20T07:21:04.089469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Norm(object):\n",
    "    def __init__(self, max=255):\n",
    "        self.max = max\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        video_x = sample\n",
    "        new_video_x = video_x / self.max\n",
    "        return new_video_x\n",
    "\n",
    "\n",
    "class ToTensor(object):\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        video_x = sample\n",
    "        video_x = video_x.transpose((0, 3, 1, 2))\n",
    "        video_x = np.array(video_x)\n",
    "        return torch.from_numpy(video_x).float()\n",
    "    \n",
    "\n",
    "class Resize(object):\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        imgs_out = np.zeros((\n",
    "            sample.shape[0], configs.img_height, configs.img_width, sample.shape[3]))\n",
    "        for i in range(sample.shape[0]):\n",
    "            imgs_out[i,:,:,:] = resize(sample[i,:,:,:], imgs_out.shape[1:])\n",
    "        return imgs_out\n",
    "    \n",
    "class Resize2(object):\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        imgs_out = np.zeros((\n",
    "            sample.shape[0], 640, 480, sample.shape[3]))\n",
    "        for i in range(sample.shape[0]):\n",
    "            imgs_out[i,:,:,:] = resize(sample[i,:,:,:], imgs_out.shape[1:])\n",
    "        return imgs_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba8a8d5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T07:21:04.200897Z",
     "iopub.status.busy": "2022-06-20T07:21:04.199940Z",
     "iopub.status.idle": "2022-06-20T07:21:04.201905Z",
     "shell.execute_reply": "2022-06-20T07:21:04.202307Z",
     "shell.execute_reply.started": "2022-06-20T07:19:17.396630Z"
    },
    "papermill": {
     "duration": 0.039817,
     "end_time": "2022-06-20T07:21:04.202456",
     "exception": false,
     "start_time": "2022-06-20T07:21:04.162639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TimeSeriesDatasetNpz(data.Dataset):\n",
    "    def __init__(self, root_dir, n_frames_input=10, n_frames_output=10):\n",
    "        self.n_frames_in = n_frames_input\n",
    "        self.n_frames_out = n_frames_output\n",
    "        n_frames = n_frames_input + n_frames_output\n",
    "        \n",
    "        self.file = np.load(root_dir).transpose(1,0,2,3)[..., np.newaxis].transpose(0,1,4,2,3)\n",
    "        #self.file = np.load(root_dir).transpose(1,0,4,2,3)\n",
    "            \n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.file)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        clips = torch.from_numpy(self.file[index])\n",
    "        clips = clips.type(torch.float32)\n",
    "        clips = (clips / 255)\n",
    "        return clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4d09fda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T07:21:04.277746Z",
     "iopub.status.busy": "2022-06-20T07:21:04.277051Z",
     "iopub.status.idle": "2022-06-20T07:21:04.279734Z",
     "shell.execute_reply": "2022-06-20T07:21:04.279247Z",
     "shell.execute_reply.started": "2022-06-20T07:19:17.408308Z"
    },
    "papermill": {
     "duration": 0.047092,
     "end_time": "2022-06-20T07:21:04.279859",
     "exception": false,
     "start_time": "2022-06-20T07:21:04.232767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(data.Dataset):\n",
    "    def __init__(self, root_dir, n_frames_input=10, n_frames_output=10):\n",
    "        view_type='090'\n",
    "        random.seed(1000)\n",
    "        self.n_frames_in = n_frames_input\n",
    "        self.n_frames_out = n_frames_output\n",
    "        n_frames = n_frames_input + n_frames_output\n",
    "        subject_dirs = [d for d in os.listdir(root_dir)] # [01, 02, 03]\n",
    "        subject_dirs = [os.path.join(root_dir, subject_dirs[i]) for i in range(len(subject_dirs))] # root/01/01/\n",
    "        seq_type_dirs = [os.path.join(d, sd) for d in subject_dirs for sd in os.listdir(d)] # [root/01/01/bg1, root/01/01/bg2]\n",
    "        view_type_dirs = sorted([[os.path.join(d, sd)] for d in seq_type_dirs for sd in os.listdir(d) if sd == view_type])\n",
    "\n",
    "        self.specific_view_files = []\n",
    "        print(len(view_type_dirs))\n",
    "        \n",
    "        for d in view_type_dirs:\n",
    "            self.specific_view_files.append(sorted([os.path.join(d[0], f) for f in os.listdir(d[0])]))\n",
    "        \n",
    "        self.nframes_list = []\n",
    "        for f in self.specific_view_files[:50]:\n",
    "            for i in range(len(f)-n_frames):\n",
    "                self.nframes_list.append(f[i:i+n_frames])\n",
    "        \n",
    "        self.trans_norm = transforms.Compose([Norm()])\n",
    "        self.trans_tensor = transforms.Compose([ToTensor()])\n",
    "        self.trans_resize = transforms.Compose([Resize()])\n",
    "        \n",
    "        print(len(self.nframes_list))\n",
    "            \n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.nframes_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data_seq = np.ndarray(shape=(len(self.nframes_list[index]), 64, 64), dtype=np.uint8)\n",
    "        \n",
    "        for i, f in enumerate(self.nframes_list[index]):\n",
    "            data_seq[i, :] = cv2.resize(np.array(Image.open(f)), (64, 64))\n",
    "            \n",
    "        data_seq = data_seq[..., np.newaxis]\n",
    "        input = self.trans_norm(data_seq)  \n",
    "        #input = self.trans_resize(input)\n",
    "        #input = reshape_patch(input, configs.patch_size)\n",
    "        input = self.trans_tensor(input)\n",
    "        return input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce365e2",
   "metadata": {
    "papermill": {
     "duration": 0.029889,
     "end_time": "2022-06-20T07:21:04.339743",
     "exception": false,
     "start_time": "2022-06-20T07:21:04.309854",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## TEST CASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06ef3dbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T07:21:04.404069Z",
     "iopub.status.busy": "2022-06-20T07:21:04.403298Z",
     "iopub.status.idle": "2022-06-20T07:21:04.405663Z",
     "shell.execute_reply": "2022-06-20T07:21:04.405207Z",
     "shell.execute_reply.started": "2022-06-20T07:19:17.434752Z"
    },
    "papermill": {
     "duration": 0.035424,
     "end_time": "2022-06-20T07:21:04.405768",
     "exception": false,
     "start_time": "2022-06-20T07:21:04.370344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# td = TimeSeriesDataset(root_dir='../../input/ethzzz/dataset_ETHZ/seq1', n_frames_input=10, n_frames_output=10)\n",
    "# train_loader = torch.utils.data.DataLoader(dataset=td, batch_size=3, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcfc003b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T07:21:04.470741Z",
     "iopub.status.busy": "2022-06-20T07:21:04.469953Z",
     "iopub.status.idle": "2022-06-20T07:21:04.472373Z",
     "shell.execute_reply": "2022-06-20T07:21:04.471974Z",
     "shell.execute_reply.started": "2022-06-20T07:19:17.452194Z"
    },
    "papermill": {
     "duration": 0.035728,
     "end_time": "2022-06-20T07:21:04.472503",
     "exception": false,
     "start_time": "2022-06-20T07:21:04.436775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# z = next(iter(train_loader))\n",
    "# print(z.shape)\n",
    "# print(torch.max(z), torch.min(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34a9b7d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T07:21:04.565806Z",
     "iopub.status.busy": "2022-06-20T07:21:04.564477Z",
     "iopub.status.idle": "2022-06-20T07:21:04.566503Z",
     "shell.execute_reply": "2022-06-20T07:21:04.565151Z",
     "shell.execute_reply.started": "2022-06-20T07:19:17.459111Z"
    },
    "papermill": {
     "duration": 0.06257,
     "end_time": "2022-06-20T07:21:04.566647",
     "exception": false,
     "start_time": "2022-06-20T07:21:04.504077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.imshow(z[0][0].permute(1,2,0)) \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443f9b20",
   "metadata": {
    "papermill": {
     "duration": 0.061218,
     "end_time": "2022-06-20T07:21:04.691569",
     "exception": false,
     "start_time": "2022-06-20T07:21:04.630351",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **DEPTH**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "019d13e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T07:21:04.816582Z",
     "iopub.status.busy": "2022-06-20T07:21:04.815477Z",
     "iopub.status.idle": "2022-06-20T07:21:04.818219Z",
     "shell.execute_reply": "2022-06-20T07:21:04.817426Z",
     "shell.execute_reply.started": "2022-06-20T07:19:17.468233Z"
    },
    "papermill": {
     "duration": 0.068356,
     "end_time": "2022-06-20T07:21:04.818375",
     "exception": false,
     "start_time": "2022-06-20T07:21:04.750019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "deb9c089",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T07:21:04.941448Z",
     "iopub.status.busy": "2022-06-20T07:21:04.940444Z",
     "iopub.status.idle": "2022-06-20T07:21:04.943081Z",
     "shell.execute_reply": "2022-06-20T07:21:04.942297Z",
     "shell.execute_reply.started": "2022-06-20T07:19:17.477526Z"
    },
    "papermill": {
     "duration": 0.065303,
     "end_time": "2022-06-20T07:21:04.943249",
     "exception": false,
     "start_time": "2022-06-20T07:21:04.877946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import gdown\n",
    "\n",
    "# !git clone 'https://github.com/shariqfarooq123/AdaBins'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05e0e014",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T07:21:05.063645Z",
     "iopub.status.busy": "2022-06-20T07:21:05.062602Z",
     "iopub.status.idle": "2022-06-20T07:21:05.064542Z",
     "shell.execute_reply": "2022-06-20T07:21:05.065536Z",
     "shell.execute_reply.started": "2022-06-20T07:19:17.484221Z"
    },
    "papermill": {
     "duration": 0.064806,
     "end_time": "2022-06-20T07:21:05.065718",
     "exception": false,
     "start_time": "2022-06-20T07:21:05.000912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %cd AdaBins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9dbe346",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T07:21:05.184665Z",
     "iopub.status.busy": "2022-06-20T07:21:05.183685Z",
     "iopub.status.idle": "2022-06-20T07:21:05.186177Z",
     "shell.execute_reply": "2022-06-20T07:21:05.185536Z",
     "shell.execute_reply.started": "2022-06-20T07:19:17.504767Z"
    },
    "papermill": {
     "duration": 0.063378,
     "end_time": "2022-06-20T07:21:05.186288",
     "exception": false,
     "start_time": "2022-06-20T07:21:05.122910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !gdown https://drive.google.com/uc?id=1lvyZZbC9NLcS8a__YPcUP7rDiIpbRpoF\n",
    "# !mkdir pretrained\n",
    "# !mv AdaBins_nyu.pt pretrained/AdaBins_nyu.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3108701a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T07:21:05.257799Z",
     "iopub.status.busy": "2022-06-20T07:21:05.256781Z",
     "iopub.status.idle": "2022-06-20T07:21:05.259853Z",
     "shell.execute_reply": "2022-06-20T07:21:05.259250Z",
     "shell.execute_reply.started": "2022-06-20T07:19:17.517622Z"
    },
    "papermill": {
     "duration": 0.039111,
     "end_time": "2022-06-20T07:21:05.259976",
     "exception": false,
     "start_time": "2022-06-20T07:21:05.220865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from infer import InferenceHelper\n",
    "\n",
    "# infer_helper = InferenceHelper(dataset='nyu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b00dd7a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T07:21:05.331316Z",
     "iopub.status.busy": "2022-06-20T07:21:05.330374Z",
     "iopub.status.idle": "2022-06-20T07:21:05.332223Z",
     "shell.execute_reply": "2022-06-20T07:21:05.332787Z",
     "shell.execute_reply.started": "2022-06-20T07:19:17.527468Z"
    },
    "papermill": {
     "duration": 0.03901,
     "end_time": "2022-06-20T07:21:05.332910",
     "exception": false,
     "start_time": "2022-06-20T07:21:05.293900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [os.path.join('../../input/ethzzz/dataset_ETHZ/seq1', d) for d in os.listdir('../../input/ethzzz/dataset_ETHZ/seq1')][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb5883a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T07:21:05.403896Z",
     "iopub.status.busy": "2022-06-20T07:21:05.402774Z",
     "iopub.status.idle": "2022-06-20T07:21:05.406895Z",
     "shell.execute_reply": "2022-06-20T07:21:05.406358Z",
     "shell.execute_reply.started": "2022-06-20T07:19:17.537999Z"
    },
    "papermill": {
     "duration": 0.040177,
     "end_time": "2022-06-20T07:21:05.407019",
     "exception": false,
     "start_time": "2022-06-20T07:21:05.366842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !mkdir output_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d2862c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T07:21:05.478299Z",
     "iopub.status.busy": "2022-06-20T07:21:05.477546Z",
     "iopub.status.idle": "2022-06-20T07:21:05.479872Z",
     "shell.execute_reply": "2022-06-20T07:21:05.480379Z",
     "shell.execute_reply.started": "2022-06-20T07:19:17.547169Z"
    },
    "papermill": {
     "duration": 0.039355,
     "end_time": "2022-06-20T07:21:05.480519",
     "exception": false,
     "start_time": "2022-06-20T07:21:05.441164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#infer_helper.predict_dir(\"../../input/ethzzz/dataset_ETHZ/seq1/p001/\", \"../output_depth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28d7ded8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T07:21:05.551563Z",
     "iopub.status.busy": "2022-06-20T07:21:05.550728Z",
     "iopub.status.idle": "2022-06-20T07:21:05.552768Z",
     "shell.execute_reply": "2022-06-20T07:21:05.553221Z",
     "shell.execute_reply.started": "2022-06-20T07:19:17.556978Z"
    },
    "papermill": {
     "duration": 0.039641,
     "end_time": "2022-06-20T07:21:05.553340",
     "exception": false,
     "start_time": "2022-06-20T07:21:05.513699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# example_rgb_batch = next(iter(train_loader)).to(configs.device)\n",
    "# print(example_rgb_batch[:,0,:].shape)\n",
    "# bin_centers, predicted_depth = infer_helper.predict(example_rgb_batch[:,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76c16b5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T07:21:05.623891Z",
     "iopub.status.busy": "2022-06-20T07:21:05.622925Z",
     "iopub.status.idle": "2022-06-20T07:21:05.625130Z",
     "shell.execute_reply": "2022-06-20T07:21:05.625622Z",
     "shell.execute_reply.started": "2022-06-20T07:19:17.566314Z"
    },
    "papermill": {
     "duration": 0.0393,
     "end_time": "2022-06-20T07:21:05.625742",
     "exception": false,
     "start_time": "2022-06-20T07:21:05.586442",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.imshow(example_rgb_batch[0,0,:].cpu().permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46067be9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T07:21:05.696734Z",
     "iopub.status.busy": "2022-06-20T07:21:05.695748Z",
     "iopub.status.idle": "2022-06-20T07:21:05.699328Z",
     "shell.execute_reply": "2022-06-20T07:21:05.698773Z",
     "shell.execute_reply.started": "2022-06-20T07:19:17.576983Z"
    },
    "papermill": {
     "duration": 0.039725,
     "end_time": "2022-06-20T07:21:05.699477",
     "exception": false,
     "start_time": "2022-06-20T07:21:05.659752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.imshow(predicted_depth[0][0], cmap='plasma')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ce7138",
   "metadata": {
    "papermill": {
     "duration": 0.033222,
     "end_time": "2022-06-20T07:21:05.765772",
     "exception": false,
     "start_time": "2022-06-20T07:21:05.732550",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **MODELS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f069c8e",
   "metadata": {
    "papermill": {
     "duration": 0.033787,
     "end_time": "2022-06-20T07:21:05.833796",
     "exception": false,
     "start_time": "2022-06-20T07:21:05.800009",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## MAU-CELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "447cb3e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T07:21:05.905803Z",
     "iopub.status.busy": "2022-06-20T07:21:05.904959Z",
     "iopub.status.idle": "2022-06-20T07:21:05.907375Z",
     "shell.execute_reply": "2022-06-20T07:21:05.906972Z",
     "shell.execute_reply.started": "2022-06-20T07:19:17.585301Z"
    },
    "papermill": {
     "duration": 0.039964,
     "end_time": "2022-06-20T07:21:05.907509",
     "exception": false,
     "start_time": "2022-06-20T07:21:05.867545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ix = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a551ceb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T07:21:05.999551Z",
     "iopub.status.busy": "2022-06-20T07:21:05.979272Z",
     "iopub.status.idle": "2022-06-20T07:21:06.001894Z",
     "shell.execute_reply": "2022-06-20T07:21:06.002574Z",
     "shell.execute_reply.started": "2022-06-20T07:19:17.591932Z"
    },
    "papermill": {
     "duration": 0.060996,
     "end_time": "2022-06-20T07:21:06.002710",
     "exception": false,
     "start_time": "2022-06-20T07:21:05.941714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MAUCell(nn.Module):\n",
    "    def __init__(self, in_channel, num_hidden, height, width, filter_size, stride, tau, cell_mode):\n",
    "        super(MAUCell, self).__init__()\n",
    "        \n",
    "        self.num_hidden = num_hidden\n",
    "        self.padding = (filter_size[0] // 2, filter_size[1] // 2)\n",
    "        self.cell_mode = cell_mode\n",
    "        self.d = num_hidden * height * width\n",
    "        self.tau = tau\n",
    "        self.states = ['residual', 'normal']\n",
    "        if not self.cell_mode in self.states:\n",
    "            raise AssertionError\n",
    "        self.conv_t = nn.Sequential(\n",
    "            nn.Conv2d(in_channel, 4 * num_hidden, kernel_size=filter_size, stride=stride, padding=self.padding),\n",
    "            nn.LayerNorm([4 * num_hidden, height, width])\n",
    "        )\n",
    "        self.conv_t_next = nn.Sequential(\n",
    "            nn.Conv2d(in_channel, num_hidden, kernel_size=filter_size, stride=stride, padding=self.padding),\n",
    "            nn.LayerNorm([num_hidden, height, width])\n",
    "        )\n",
    "        \n",
    "        self.conv_s = nn.Sequential(\n",
    "            nn.Conv2d(num_hidden, 4 * num_hidden, kernel_size=filter_size, stride=stride, padding=self.padding),\n",
    "            nn.LayerNorm([4 * num_hidden, height, width])\n",
    "        )\n",
    "        \n",
    "        self.conv_s_next = nn.Sequential(\n",
    "            nn.Conv2d(num_hidden, num_hidden, kernel_size=filter_size, stride=stride, padding=self.padding),\n",
    "            nn.LayerNorm([num_hidden, height, width])\n",
    "        )\n",
    "        \n",
    "        self.conv_t_i = nn.Sequential(\n",
    "            nn.Conv2d(num_hidden, num_hidden, kernel_size=filter_size, stride=stride, padding=self.padding),\n",
    "            nn.LayerNorm([num_hidden, height, width])\n",
    "        )\n",
    "        \n",
    "        self.alpha_s = nn.Parameter(torch.randn(1))\n",
    "        self.alpha_t = nn.Parameter(torch.randn(1))\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "\n",
    "        \n",
    "    def forward(self, T_t, S_t, t_att, s_att, s_pixel_att):\n",
    "        global ix\n",
    "        s_next = self.conv_s_next(S_t)\n",
    "        t_next = self.conv_t_next(T_t)\n",
    "\n",
    "        weights_list = []\n",
    "        for i in range(self.tau):\n",
    "            weights_list.append((s_att[i] * s_next).sum(dim=(1, 2, 3)) / math.sqrt(self.d))\n",
    "        weights_list = torch.stack(weights_list, dim=0)\n",
    "        weights_list = torch.reshape(weights_list, (*weights_list.shape, 1, 1, 1))\n",
    "        weights_list = self.softmax(weights_list)\n",
    "\n",
    "        T_trend = t_att * weights_list\n",
    "        T_trend = T_trend.sum(dim=0)\n",
    "        t_att_gate = torch.sigmoid(t_next)\n",
    "        s_att_gate = torch.sigmoid(s_next)\n",
    "        \n",
    "        T_fusion = T_t * t_att_gate + (1 - t_att_gate) * T_trend\n",
    "        #S_fusion = S_t * s_att_gate + (1 - s_att_gate) * torch.sigmoid(s_pixel_att) * T_trend\n",
    "        #S_fusion = S_t * s_att_gate + (1 - s_att_gate) * s_pixel_att\n",
    "        S_fusion = S_t * torch.sigmoid(s_pixel_att)\n",
    "        \n",
    "        T_concat = self.conv_t(T_fusion)\n",
    "        S_concat = self.conv_s(S_fusion)\n",
    "\n",
    "        t_i, t_r, t_t, t_s = torch.split(T_concat, self.num_hidden, dim=1)\n",
    "        s_i, s_r, s_t, s_s = torch.split(S_concat, self.num_hidden, dim=1)\n",
    "\n",
    "#         T_c = torch.tanh(T_fusion*t_r)\n",
    "#         S_c = torch.tanh(S_fusion*s_r)\n",
    "        \n",
    "        T_i = torch.tanh(t_i)\n",
    "        S_i = torch.tanh(s_i)\n",
    "        \n",
    "        T_r = torch.sigmoid(t_r)\n",
    "        S_r = torch.sigmoid(t_r)\n",
    "        \n",
    "        T_t = torch.sigmoid(t_t)\n",
    "        S_s = torch.sigmoid(s_s)\n",
    "        \n",
    "        T_s = torch.sigmoid(t_s)\n",
    "        S_t = torch.sigmoid(s_t)\n",
    "\n",
    "        T_new_1 = T_r * T_i + S_t * T_fusion\n",
    "        S_new_1 = S_r * S_i + T_s * S_fusion\n",
    "\n",
    "        T_new_2 = T_r * t_i + (1 - T_r) * s_t\n",
    "        S_new_2 = S_r * s_i + (1 - S_r) * t_s\n",
    "        \n",
    "        if ix % 9000 == 0:\n",
    "            print(self.alpha_s.item(), self.alpha_t.item())\n",
    "                \n",
    "        out_S = self.alpha_s*S_new_1 + (1-self.alpha_s)*S_new_2\n",
    "        out_T = self.alpha_t*T_new_1 + (1-self.alpha_t)*T_new_2\n",
    "\n",
    "        #if self.cell_mode == 'residual':\n",
    "           # S_new = S_t + S_new\n",
    "        ix += 1\n",
    "        return out_T, out_S\n",
    "        #return T_new_2, S_new_2\n",
    "        #return T_new_1, S_new_1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a29b9c",
   "metadata": {
    "papermill": {
     "duration": 0.033818,
     "end_time": "2022-06-20T07:21:06.070436",
     "exception": false,
     "start_time": "2022-06-20T07:21:06.036618",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## MAU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28b899ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T07:21:06.148516Z",
     "iopub.status.busy": "2022-06-20T07:21:06.143034Z",
     "iopub.status.idle": "2022-06-20T07:21:06.193666Z",
     "shell.execute_reply": "2022-06-20T07:21:06.193020Z",
     "shell.execute_reply.started": "2022-06-20T07:19:17.640671Z"
    },
    "papermill": {
     "duration": 0.089118,
     "end_time": "2022-06-20T07:21:06.193859",
     "exception": false,
     "start_time": "2022-06-20T07:21:06.104741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, num_layers, num_hidden, configs):\n",
    "        super(RNN, self).__init__()\n",
    "        # print(configs.srcnn_tf)\n",
    "        self.configs = configs\n",
    "        self.frame_channel = configs.img_channel\n",
    "        self.num_layers = num_layers\n",
    "        self.num_hidden = num_hidden\n",
    "        self.tau = configs.tau\n",
    "        self.cell_mode = configs.cell_mode\n",
    "        self.states = ['recall', 'normal']\n",
    "        if not self.configs.model_mode in self.states:\n",
    "            raise AssertionError\n",
    "        # self.time = 2\n",
    "        cell_list = []\n",
    "\n",
    "        width = configs.img_width // configs.sr_size\n",
    "        height = configs.img_height // configs.sr_size\n",
    "        # print(width)\n",
    "\n",
    "        for i in range(num_layers):\n",
    "            in_channel = num_hidden[i - 1]\n",
    "            cell_list.append(\n",
    "                MAUCell(in_channel, num_hidden[i], height, width, configs.filter_size,\n",
    "                        configs.stride, self.tau, self.cell_mode)\n",
    "            )\n",
    "        self.cell_list = nn.ModuleList(cell_list)\n",
    "\n",
    "        # Encoder\n",
    "        n = int(math.log2(configs.sr_size))\n",
    "        encoders = []\n",
    "        encoder = nn.Sequential()\n",
    "        encoder.add_module(name='encoder_t_conv{0}'.format(-1),\n",
    "                           module=nn.Conv2d(in_channels=self.frame_channel,\n",
    "                                            out_channels=self.num_hidden[0],\n",
    "                                            stride=1,\n",
    "                                            padding=0,\n",
    "                                            kernel_size=1))\n",
    "        encoder.add_module(name='relu_t_{0}'.format(-1),\n",
    "                           module=nn.LeakyReLU(0.2))\n",
    "        encoders.append(encoder)\n",
    "        for i in range(n):\n",
    "            encoder = nn.Sequential()\n",
    "            encoder.add_module(name='encoder_t{0}'.format(i),\n",
    "                               module=nn.Conv2d(in_channels=self.num_hidden[0],\n",
    "                                                out_channels=self.num_hidden[0],\n",
    "                                                stride=(2, 2),\n",
    "                                                padding=(1, 1),\n",
    "                                                kernel_size=(3, 3)\n",
    "                                                ))\n",
    "            # self.encoder_t.add_module(name='gn_t{0}'.format(i),\n",
    "            #                           module=nn.GroupNorm(4, self.frame_channel))\n",
    "            encoder.add_module(name='encoder_t_relu{0}'.format(i),\n",
    "                               module=nn.LeakyReLU(0.2))\n",
    "            encoders.append(encoder)\n",
    "        self.encoders = nn.ModuleList(encoders)\n",
    "\n",
    "        # Decoder\n",
    "        decoders = []\n",
    "\n",
    "        for i in range(n - 1):\n",
    "            decoder = nn.Sequential()\n",
    "            decoder.add_module(name='c_decoder{0}'.format(i),\n",
    "                               module=nn.ConvTranspose2d(in_channels=self.num_hidden[-1],\n",
    "                                                         out_channels=self.num_hidden[-1],\n",
    "                                                         stride=(2, 2),\n",
    "                                                         padding=(1, 1),\n",
    "                                                         kernel_size=(3, 3),\n",
    "                                                         output_padding=(1, 1)\n",
    "                                                         ))\n",
    "            # self.decoder_s.add_module(name='gn_decoder_s{0}'.format(i),\n",
    "            #                           module=nn.GroupNorm(4, self.frame_channel))\n",
    "            decoder.add_module(name='c_decoder_relu{0}'.format(i),\n",
    "                               module=nn.LeakyReLU(0.2))\n",
    "            decoders.append(decoder)\n",
    "\n",
    "        if n > 0:\n",
    "            decoder = nn.Sequential()\n",
    "            decoder.add_module(name='c_decoder{0}'.format(n - 1),\n",
    "                               module=nn.ConvTranspose2d(in_channels=self.num_hidden[-1],\n",
    "                                                         out_channels=self.num_hidden[-1],\n",
    "                                                         stride=(2, 2),\n",
    "                                                         padding=(1, 1),\n",
    "                                                         kernel_size=(3, 3),\n",
    "                                                         output_padding=(1, 1)\n",
    "                                                         ))\n",
    "            decoders.append(decoder)\n",
    "        self.decoders = nn.ModuleList(decoders)\n",
    "\n",
    "        self.srcnn = nn.Sequential(\n",
    "            nn.Conv2d(self.num_hidden[-1], self.frame_channel, kernel_size=1, stride=1, padding=0)\n",
    "        )\n",
    "        self.merge = nn.Conv2d(self.num_hidden[-1] * 2, self.num_hidden[-1], kernel_size=1, stride=1, padding=0)\n",
    "        self.conv_last_sr = nn.Conv2d(self.frame_channel * 2, self.frame_channel, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "\n",
    "    def forward(self, frames, mask_true, verbose=False):\n",
    "        # print('ok')\n",
    "        mask_true = mask_true.permute(0, 1, 4, 2, 3).contiguous()\n",
    "        if(verbose):\n",
    "            print('MT Permuted to: ',  mask_true.shape)\n",
    "        batch_size = frames.shape[0]\n",
    "        height = frames.shape[3] // self.configs.sr_size\n",
    "        width = frames.shape[4] // self.configs.sr_size\n",
    "        frame_channels = frames.shape[2]\n",
    "        next_frames = []\n",
    "        T_t = []\n",
    "        T_pre = []\n",
    "        S_pre = []\n",
    "        # H_t = []\n",
    "        x_gen = None\n",
    "        if(verbose):\n",
    "            print('Num Layers: ', self.num_layers)\n",
    "            print('Num Hidden: ', self.num_hidden)\n",
    "            print('TAU: ', self.tau)\n",
    "        for layer_idx in range(self.num_layers):\n",
    "            tmp_t = []\n",
    "            tmp_s = []\n",
    "            if layer_idx == 0:\n",
    "                in_channel = self.num_hidden[layer_idx]\n",
    "            else:\n",
    "                in_channel = self.num_hidden[layer_idx - 1]\n",
    "            for i in range(self.tau):\n",
    "                if(verbose):\n",
    "                    if i==2:\n",
    "                        print('tmp_t[1]', tmp_t[1].shape)\n",
    "                tmp_t.append(torch.zeros([batch_size, in_channel, height, width]).to(self.configs.device))\n",
    "                tmp_s.append(torch.zeros([batch_size, in_channel, height, width]).to(self.configs.device))\n",
    "            T_pre.append(tmp_t)\n",
    "            S_pre.append(tmp_s)\n",
    "\n",
    "        if(verbose):\n",
    "            print('len T_pre', len(T_pre))\n",
    "            print('len T_pre[1]', len(T_pre[1]))\n",
    "\n",
    "        S_t_previ = torch.zeros([batch_size, in_channel, height, width]).to(self.configs.device)\n",
    "            \n",
    "        for t in range(self.configs.total_length - 1):\n",
    "            if t < self.configs.input_length:\n",
    "                net = frames[:, t]\n",
    "                if(verbose):\n",
    "                    print('Net frames[:, t]', frames[:, t].shape)\n",
    "            else:\n",
    "                time_diff = t - self.configs.input_length\n",
    "                net = mask_true[:, time_diff] * frames[:, t] + (1 - mask_true[:, time_diff]) * x_gen\n",
    "                if(verbose):\n",
    "                    print('Net', net.shape)\n",
    "\n",
    "            frames_feature = net\n",
    "            frames_feature_encoded = []\n",
    "            if(verbose):\n",
    "                print('Len Encoders', len(self.encoders))\n",
    "            for i in range(len(self.encoders)):\n",
    "                frames_feature = self.encoders[i](frames_feature)\n",
    "                if(verbose):\n",
    "                    print('Frames_feature', i, frames_feature.shape)\n",
    "                frames_feature_encoded.append(frames_feature)\n",
    "            if t == 0:\n",
    "                for i in range(self.num_layers):\n",
    "                    zeros = torch.zeros([batch_size, self.num_hidden[i], height, width]).to(self.configs.device)\n",
    "                    T_t.append(zeros)\n",
    "                    # print('ok')\n",
    "            S_t = frames_feature\n",
    "            if(verbose):\n",
    "                print('S_t in', S_t.shape)\n",
    "            \n",
    "            S_pixel_att = torch.sum((S_t - S_t_previ)**2)\n",
    "            S_t_previ = S_t\n",
    "            \n",
    "                \n",
    "            for i in range(self.num_layers):\n",
    "                t_att = T_pre[i][-self.tau:]\n",
    "                t_att = torch.stack(t_att, dim=0)\n",
    "                s_att = S_pre[i][-self.tau:]\n",
    "                s_att = torch.stack(s_att, dim=0)\n",
    "                S_pre[i].append(S_t)\n",
    "                if i < 2 and verbose:\n",
    "                    print('T_t', len(T_t))\n",
    "                    print('T_t[i], S_t, t_att, s_att', T_t[i].shape, S_t.shape, t_att.shape, s_att.shape)\n",
    "                T_t[i], S_t = self.cell_list[i](T_t[i], S_t, t_att, s_att, S_pixel_att)\n",
    "                T_pre[i].append(T_t[i])\n",
    "                # S_pre[i].append(S_t)\n",
    "            out = S_t\n",
    "            if(verbose):\n",
    "                print('S_t out', S_t.shape)\n",
    "            # out = self.merge(torch.cat([T_t[-1], S_t], dim=1))\n",
    "            frames_feature_decoded = []\n",
    "            for i in range(len(self.decoders)):\n",
    "                out = self.decoders[i](out)\n",
    "                if(verbose):\n",
    "                    print('S_t out', i, out.shape)\n",
    "                # print(\"ok\")\n",
    "                if self.configs.model_mode == 'recall':\n",
    "                    # print('unet')\n",
    "                    out = out + frames_feature_encoded[-2 - i]\n",
    "                    if(verbose):\n",
    "                        print('S_t out unet', i, out.shape)\n",
    "            # out = self.decoder(out)\n",
    "\n",
    "            x_gen = self.srcnn(out)\n",
    "            next_frames.append(x_gen)\n",
    "            if(verbose):\n",
    "                print('x_gen', x_gen.shape)\n",
    "                print('len next_frames', len(next_frames))\n",
    "        if(verbose):\n",
    "            print('len next_frames FULL', len(next_frames))\n",
    "        next_frames = torch.stack(next_frames, dim=0)\n",
    "        if(verbose):\n",
    "            print('next_frames Tensor', next_frames.shape)\n",
    "        next_frames = next_frames.permute(1, 0, 2, 3, 4).contiguous()\n",
    "        if(verbose):\n",
    "            print('next_frames Tensor Permuted', next_frames.shape)\n",
    "        return next_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69aecfd",
   "metadata": {
    "papermill": {
     "duration": 0.034183,
     "end_time": "2022-06-20T07:21:06.265165",
     "exception": false,
     "start_time": "2022-06-20T07:21:06.230982",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## DISCRIMINATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5465cd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T07:21:06.337130Z",
     "iopub.status.busy": "2022-06-20T07:21:06.336173Z",
     "iopub.status.idle": "2022-06-20T07:21:06.498303Z",
     "shell.execute_reply": "2022-06-20T07:21:06.497745Z",
     "shell.execute_reply.started": "2022-06-20T07:19:17.760277Z"
    },
    "papermill": {
     "duration": 0.198824,
     "end_time": "2022-06-20T07:21:06.498523",
     "exception": false,
     "start_time": "2022-06-20T07:21:06.299699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FDU(nn.Module):\n",
    "    def __init__(self, num_layers, num_hidden, configs):\n",
    "        super(FDU, self).__init__()\n",
    "\n",
    "        self.configs = configs\n",
    "        self.frame_channel = configs.img_channel\n",
    "        self.num_layers = num_layers\n",
    "        self.num_hidden = num_hidden\n",
    "        self.tau = configs.tau\n",
    "        self.cell_mode = configs.cell_mode\n",
    "\n",
    "        cell_list = []\n",
    "\n",
    "        width = configs.img_width // configs.sr_size\n",
    "        height = configs.img_height // configs.sr_size\n",
    "\n",
    "        for i in range(num_layers):\n",
    "            in_channel = num_hidden[i - 1]\n",
    "            cell_list.append(\n",
    "                MAUCell(in_channel, num_hidden[i], height, width, configs.filter_size,\n",
    "                        configs.stride, self.tau, self.cell_mode)\n",
    "            )\n",
    "        self.cell_list = nn.ModuleList(cell_list)\n",
    "\n",
    "        # Encoder\n",
    "        n = int(math.log2(configs.sr_size))\n",
    "        encoders = []\n",
    "        encoder = nn.Sequential()\n",
    "        encoder.add_module(name='encoder_t_conv{0}'.format(-1),\n",
    "                           module=nn.Conv2d(in_channels=self.frame_channel,\n",
    "                                            out_channels=self.num_hidden[0],\n",
    "                                            stride=1,\n",
    "                                            padding=0,\n",
    "                                            kernel_size=1))\n",
    "        encoder.add_module(name='relu_t_{0}'.format(-1),\n",
    "                           module=nn.LeakyReLU(0.2))\n",
    "        encoders.append(encoder)\n",
    "        for i in range(n):\n",
    "            encoder = nn.Sequential()\n",
    "            encoder.add_module(name='encoder_t{0}'.format(i),\n",
    "                               module=nn.Conv2d(in_channels=self.num_hidden[0],\n",
    "                                                out_channels=self.num_hidden[0],\n",
    "                                                stride=(2, 2),\n",
    "                                                padding=(1, 1),\n",
    "                                                kernel_size=(3, 3)\n",
    "                                                ))\n",
    "            # self.encoder_t.add_module(name='gn_t{0}'.format(i),\n",
    "            #                           module=nn.GroupNorm(4, self.frame_channel))\n",
    "            encoder.add_module(name='encoder_t_relu{0}'.format(i),\n",
    "                               module=nn.LeakyReLU(0.2))\n",
    "            encoders.append(encoder)\n",
    "        self.encoders = nn.ModuleList(encoders)\n",
    "\n",
    "\n",
    "    def forward(self, frames, verbose=False):\n",
    "        if(verbose):\n",
    "            print('MT Permuted to: ',  mask_true.shape)\n",
    "        batch_size = frames.shape[0]\n",
    "        height = frames.shape[3] // self.configs.sr_size\n",
    "        width = frames.shape[4] // self.configs.sr_size\n",
    "        frame_channels = frames.shape[2]\n",
    "        next_frames = []\n",
    "        next_memory = []\n",
    "        T_t = []\n",
    "        T_pre = []\n",
    "        S_pre = []\n",
    "        # H_t = []\n",
    "        x_gen = None\n",
    "        if(verbose):\n",
    "            print('Num Layers: ', self.num_layers)\n",
    "            print('Num Hidden: ', self.num_hidden)\n",
    "            print('TAU: ', self.tau)\n",
    "        for layer_idx in range(self.num_layers):\n",
    "            tmp_t = []\n",
    "            tmp_s = []\n",
    "            if layer_idx == 0:\n",
    "                in_channel = self.num_hidden[layer_idx]\n",
    "            else:\n",
    "                in_channel = self.num_hidden[layer_idx - 1]\n",
    "            for i in range(self.tau):\n",
    "                if(verbose):\n",
    "                    if i==2:\n",
    "                        print('tmp_t[1]', tmp_t[1].shape)\n",
    "                tmp_t.append(torch.zeros([batch_size, in_channel, height, width]).to(self.configs.device))\n",
    "                tmp_s.append(torch.zeros([batch_size, in_channel, height, width]).to(self.configs.device))\n",
    "            T_pre.append(tmp_t)\n",
    "            S_pre.append(tmp_s)\n",
    "\n",
    "        if(verbose):\n",
    "            print('len T_pre', len(T_pre))\n",
    "            print('len T_pre[1]', len(T_pre[1]))\n",
    "\n",
    "        S_t_previ = torch.zeros([batch_size, in_channel, height, width]).to(self.configs.device)\n",
    "            \n",
    "        for t in range(self.configs.total_length - 1):\n",
    "            net = frames[:, t]\n",
    "            frames_feature = net\n",
    "            frames_feature_encoded = []\n",
    "            \n",
    "            if(verbose):\n",
    "                print('Len Encoders', len(self.encoders))\n",
    "                \n",
    "            for i in range(len(self.encoders)):\n",
    "                frames_feature = self.encoders[i](frames_feature)\n",
    "                if(verbose):\n",
    "                    print('Frames_feature', i, frames_feature.shape)\n",
    "                frames_feature_encoded.append(frames_feature)\n",
    "            if t == 0:\n",
    "                for i in range(self.num_layers):\n",
    "                    zeros = torch.zeros([batch_size, self.num_hidden[i], height, width]).to(self.configs.device)\n",
    "                    T_t.append(zeros)\n",
    "                    \n",
    "            S_t = frames_feature\n",
    "            if(verbose):\n",
    "                print('S_t in', S_t.shape)\n",
    "            \n",
    "            S_pixel_att = torch.sum((S_t - S_t_previ)**2)\n",
    "            S_t_previ = S_t\n",
    "            \n",
    "                \n",
    "            for i in range(self.num_layers):\n",
    "                t_att = T_pre[i][-self.tau:]\n",
    "                t_att = torch.stack(t_att, dim=0)\n",
    "                s_att = S_pre[i][-self.tau:]\n",
    "                s_att = torch.stack(s_att, dim=0)\n",
    "                S_pre[i].append(S_t)\n",
    "                if i < 2 and verbose:\n",
    "                    print('T_t', len(T_t))\n",
    "                    print('T_t[i], S_t, t_att, s_att', T_t[i].shape, S_t.shape, t_att.shape, s_att.shape)\n",
    "                T_t[i], S_t = self.cell_list[i](T_t[i], S_t, t_att, s_att, S_pixel_att)\n",
    "                T_pre[i].append(T_t[i])\n",
    "\n",
    "            next_frames.append(S_t)\n",
    "            next_memory.append(T_t[-1])\n",
    "            \n",
    "        next_frames = torch.stack(next_frames, dim=0).permute(1, 0, 2, 3, 4)\n",
    "        next_memory = torch.stack(next_memory, dim=0).permute(1, 0, 2, 3, 4)\n",
    "        next_all = torch.cat([next_frames, next_memory], dim=2)\n",
    "        return next_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7be8bc",
   "metadata": {
    "papermill": {
     "duration": 0.03313,
     "end_time": "2022-06-20T07:21:06.566076",
     "exception": false,
     "start_time": "2022-06-20T07:21:06.532946",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **TRAIN TEST WRAPPER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "35e6b01f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T07:21:06.637448Z",
     "iopub.status.busy": "2022-06-20T07:21:06.636543Z",
     "iopub.status.idle": "2022-06-20T07:21:06.653540Z",
     "shell.execute_reply": "2022-06-20T07:21:06.652934Z",
     "shell.execute_reply.started": "2022-06-20T07:19:17.832307Z"
    },
    "papermill": {
     "duration": 0.053486,
     "end_time": "2022-06-20T07:21:06.653677",
     "exception": false,
     "start_time": "2022-06-20T07:21:06.600191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_wrapper(model):\n",
    "    begin = 0\n",
    "\n",
    "    if args.pretrained_model_g:\n",
    "        model.load(args.pretrained_model_g, args.pretrained_model_d)\n",
    "        # begin = int(args.pretrained_model.split('-')[-1])\n",
    "        \n",
    "    # DATASET\n",
    "    dataset = TimeSeriesDataset(root_dir=configs.data_train_path, n_frames_input=10, n_frames_output=10)\n",
    "    \n",
    "    # DATA LOADER + SPLIT\n",
    "    validation_split = .3\n",
    "    shuffle_dataset = True\n",
    "    random_seed= 1000\n",
    "\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    split = int(np.floor(validation_split * dataset_size))\n",
    "    if shuffle_dataset :\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "    train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "    # Creating PT data samplers and loaders:\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    valid_sampler = SubsetRandomSampler(val_indices)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset, args.batch_size, sampler=train_sampler, num_workers=2, pin_memory=True)\n",
    "    valid_loader = torch.utils.data.DataLoader(dataset, batch_size=4, sampler=valid_sampler)\n",
    "\n",
    "    losses_l1 = []\n",
    "    losses_l2 = []\n",
    "    \n",
    "    eta = args.sampling_start_value\n",
    "    eta -= (begin * args.sampling_changing_rate)\n",
    "    itr = begin\n",
    "\n",
    "#     print('Validate:')\n",
    "    evaluation_proper(model, valid_loader, args, args.output_length)\n",
    "    #return\n",
    "    \n",
    "    for epoch in range(0, args.max_epoches):\n",
    "        for x in tqdm(train_loader, total=len(train_loader)):\n",
    "            batch_size = x.shape[0]  # (bs, frames, c, h, w)\n",
    "            eta, mask = schedule_sampling(eta, itr, args.img_channel, batch_size)\n",
    "                \n",
    "            _, loss_l1, loss_l2 = model.train(x, mask, itr, next(iter(valid_loader)), epoch)\n",
    "            \n",
    "            if itr % configs.display_interval == 0:\n",
    "                print('Step: ' + str(itr), 'T L1 loss: ' + str(loss_l1), 'T L2 loss: ' + str(loss_l2))\n",
    "                \n",
    "            losses_l1.append(loss_l1)\n",
    "            losses_l2.append(loss_l2)\n",
    "            \n",
    "            if itr % configs.plot_interval == 0:\n",
    "                fig, ax = plt.subplots(2, 1, figsize=(13, 5))\n",
    "                a = ax.flatten()\n",
    "                a[0].plot(losses_l1, 'r')\n",
    "                a[0].set_title('Loss L1 (D)')\n",
    "                a[1].plot(losses_l2, 'r')\n",
    "                a[1].set_title('Loss L2 (G)')\n",
    "                plt.show()\n",
    "            \n",
    "            if itr % args.snapshot_interval == 0 and itr > begin:\n",
    "                model.save(itr)\n",
    "            itr += 1\n",
    "            \n",
    "        if epoch >=8:\n",
    "            print('Validate:')\n",
    "            evaluation_proper(model, valid_loader, args, args.output_length)\n",
    "            #model.save(itr)\n",
    "\n",
    "\n",
    "def test_wrapper(model, valid_loader):\n",
    "    model.load(args.pretrained_model)\n",
    "\n",
    "    for i in range(1):\n",
    "        trainer.test(model, valid_loader, args, itr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774bd229",
   "metadata": {
    "papermill": {
     "duration": 0.035491,
     "end_time": "2022-06-20T07:21:06.722849",
     "exception": false,
     "start_time": "2022-06-20T07:21:06.687358",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **MODEL FACTORY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b0c8e10d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T07:21:06.837062Z",
     "iopub.status.busy": "2022-06-20T07:21:06.800972Z",
     "iopub.status.idle": "2022-06-20T07:21:06.841757Z",
     "shell.execute_reply": "2022-06-20T07:21:06.842183Z",
     "shell.execute_reply.started": "2022-06-20T07:19:17.872533Z"
    },
    "papermill": {
     "duration": 0.083404,
     "end_time": "2022-06-20T07:21:06.842310",
     "exception": false,
     "start_time": "2022-06-20T07:21:06.758906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    def __init__(self, configs):\n",
    "        self.configs = configs\n",
    "        self.patch_height = configs.img_height\n",
    "        self.patch_width = configs.img_width\n",
    "        self.patch_channel = configs.img_channel\n",
    "        self.num_layers = configs.num_layers\n",
    "        networks_map = {'mau': RNN}\n",
    "        self.num_hidden = [configs.num_hidden for i in range(configs.num_layers)]\n",
    "        if configs.model_name in networks_map:\n",
    "            Network = networks_map[configs.model_name]\n",
    "            self.network = Network(self.num_layers, self.num_hidden, configs).to(configs.device)\n",
    "        else:\n",
    "            raise ValueError('Name of network unknown %s' % configs.model_name)\n",
    "\n",
    "        if args.gan:\n",
    "            self.disc = FDU(self.num_layers, self.num_hidden, configs).to(configs.device)\n",
    "            self.disc_optimizer = torch.optim.Adam(self.disc.parameters(), lr=configs.lr) #, betas=(0.5, 0.999))\n",
    "            #self.alpha = torch.linspace(1, 0, configs.max_epoches).to(configs.device)\n",
    "            #self.beta = torch.linspace(0, 1, configs.max_epoches).to(configs.device)\n",
    "            self.alpha = [1,1,1, 10, 100, 100, 100]\n",
    "            self.beta = [1,1,1, 0.1, 0.001, 0.001, 0.001]\n",
    "            \n",
    "        self.optimizer = Adam(self.network.parameters(), lr=configs.lr)\n",
    "        self.MSE_criterion = nn.MSELoss()\n",
    "        self.L1_loss = nn.L1Loss()\n",
    "        self.loss_bce = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def save(self, itr):\n",
    "        stats_g = {'net_param': self.network.state_dict()}\n",
    "        stats_d = {'net_param': self.disc.state_dict()}\n",
    "        checkpoint_path_g = os.path.join(self.configs.save_dir, 'model_g.ckpt' + '-' + str(itr))\n",
    "        checkpoint_path_d = os.path.join(self.configs.save_dir, 'model_d.ckpt' + '-' + str(itr))\n",
    "        torch.save(stats_g, checkpoint_path_g)\n",
    "        torch.save(stats_d, checkpoint_path_d)\n",
    "        #print(\"Save predictive model to %s\" % checkpoint_path)\n",
    "\n",
    "    def load(self, pm_checkpoint_path_g, pm_checkpoint_path_d):\n",
    "        print('Load predictive model:', pm_checkpoint_path_g)\n",
    "        stats = torch.load(pm_checkpoint_path_g, map_location=torch.device(self.configs.device))\n",
    "        self.network.load_state_dict(stats['net_param'])\n",
    "        stats = torch.load(pm_checkpoint_path_d, map_location=torch.device(self.configs.device))\n",
    "        self.disc.load_state_dict(stats['net_param'])\n",
    "\n",
    "    def train(self, data, mask, itr, val, ei):\n",
    "        frames = data\n",
    "        loss_d = 0\n",
    "        loss_g = 0\n",
    "        self.network.train()\n",
    "        val_tensor = torch.FloatTensor(val).to(self.configs.device)\n",
    "        frames_tensor = torch.FloatTensor(frames).to(self.configs.device)\n",
    "        mask_tensor = torch.FloatTensor(mask).to(self.configs.device)\n",
    "\n",
    "        if(self.configs.verbose):\n",
    "            print('FT', frames_tensor.shape)\n",
    "            print('MT', mask_tensor.shape)\n",
    "\n",
    "        next_frames = self.network(frames_tensor, mask_tensor)\n",
    "        if(self.configs.verbose):\n",
    "            print('Next Frames', next_frames.shape)\n",
    "\n",
    "        ground_truth = frames_tensor\n",
    "        if(self.configs.verbose):\n",
    "            print('Ground', ground_truth[:, 1:].shape)\n",
    "            \n",
    "        if args.gan:    \n",
    "            d_fake = self.disc(next_frames.detach()) #decoder_input.detach(), \n",
    "            d_real = self.disc(frames_tensor[:, 1:]) #decoder_input.detach(), \n",
    "            loss_d_real = self.loss_bce(d_real, torch.ones_like(d_real))\n",
    "            loss_d_fake = self.loss_bce(d_fake, torch.zeros_like(d_fake))\n",
    "            loss_d = loss_d_real + loss_d_fake\n",
    "\n",
    "            \n",
    "        if itr % configs.plot_interval == 0:\n",
    "            print('Epoch:', ei)\n",
    "            with torch.no_grad():\n",
    "                self.network.eval()\n",
    "                x = frames_tensor[0][0:configs.input_length]\n",
    "                y = frames_tensor[0][configs.input_length:]\n",
    "                g = next_frames[0][configs.input_length-1:]\n",
    "                m = mask_tensor[0]\n",
    "                fig, ax = plt.subplots(4, configs.input_length, figsize=(25, 10))\n",
    "                for i in range(4):\n",
    "                    for j in range(configs.input_length):\n",
    "                        if i == 0:\n",
    "                            ax[i][j].imshow(x[j].to('cpu').permute(1, 2, 0), cmap='gray')\n",
    "                            ax[i][j].set_title('T Input')\n",
    "                        if i == 1:\n",
    "                            if j == configs.input_length-1:\n",
    "                                ax[i][j].axis('off')\n",
    "                                continue\n",
    "                            ax[i][j].imshow(m[j].to('cpu'))\n",
    "                            ax[i][j].set_title('T Mask')\n",
    "                        if i == 2:\n",
    "                            ax[i][j].imshow(y[j].to('cpu').permute(1, 2, 0), cmap='gray')\n",
    "                            ax[i][j].set_title('T Ground Truth')\n",
    "                        if i == 3:\n",
    "                            ax[i][j].imshow(g[j].detach().to('cpu').permute(1, 2, 0), cmap='gray')\n",
    "                            ax[i][j].set_title('T Generated')\n",
    "                        ax[i][j].axis('off')\n",
    "\n",
    "\n",
    "                x = val_tensor[0][0:configs.input_length]\n",
    "                y = val_tensor[0][configs.input_length:]\n",
    "                mask = torch.zeros_like(mask_tensor[0]).unsqueeze(0).to(configs.device)\n",
    "                next_frameszz = self.network(val_tensor, mask)\n",
    "                m = mask[0]\n",
    "                g = next_frameszz[0][configs.input_length-1:]\n",
    "                fig, ax = plt.subplots(4, configs.input_length, figsize=(25, 10))\n",
    "                for i in range(4):\n",
    "                    for j in range(configs.input_length):\n",
    "                        if i == 0:\n",
    "                            ax[i][j].imshow(x[j].to('cpu').permute(1, 2, 0), cmap='gray')\n",
    "                            ax[i][j].set_title('V Input')\n",
    "                        if i == 1:\n",
    "                            if j == configs.input_length-1:\n",
    "                                ax[i][j].axis('off')\n",
    "                                continue\n",
    "                            ax[i][j].imshow(m[j].to('cpu'))\n",
    "                            ax[i][j].set_title('V Mask')\n",
    "                        if i == 2:\n",
    "                            ax[i][j].imshow(y[j].to('cpu').permute(1, 2, 0), cmap='gray')\n",
    "                            ax[i][j].set_title('V Ground Truth')\n",
    "                        if i == 3:\n",
    "                            ax[i][j].imshow(g[j].detach().to('cpu').permute(1, 2, 0), cmap='gray')\n",
    "                            ax[i][j].set_title('V Generated')\n",
    "                        ax[i][j].axis('off')\n",
    "                \n",
    "                self.network.train()\n",
    "        \n",
    "        if args.gan:\n",
    "            self.disc_optimizer.zero_grad()\n",
    "            loss_d.backward()\n",
    "            self.disc_optimizer.step() \n",
    "\n",
    "            \n",
    "            d_fake = self.disc(next_frames) \n",
    "            loss_g = self.loss_bce(d_fake, torch.ones_like(d_fake))\n",
    "            \n",
    "        batch_size = next_frames.shape[0]\n",
    "\n",
    "        loss_l1 = self.L1_loss(next_frames, ground_truth[:, 1:])\n",
    "        loss_l2 = self.MSE_criterion(next_frames, ground_truth[:, 1:])\n",
    "        \n",
    "        alp = self.alpha[min(len(self.alpha)-1, ei)]\n",
    "        bet = self.beta[min(len(self.beta)-1, ei)]\n",
    "        \n",
    "        if itr % configs.plot_interval == 0:\n",
    "            print('Aplha: ', alp)\n",
    "            print('Beta: ', bet)\n",
    "        \n",
    "        if args.gan:\n",
    "            #loss_gen = loss_l2*alp + loss_l1 + loss_g*bet\n",
    "            loss_gen = loss_g*1e-6 + loss_l2 + loss_l1*0.1\n",
    "            #loss_gen = loss_g*1e-6*alp + loss_l2*bet + loss_l1*0.5\n",
    "            #loss_gen = loss_g*1e-6*alp + loss_l2*bet + loss_l1*0.5\n",
    "        else:\n",
    "            loss_gen = loss_l2 # + loss_l1*0.5\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        loss_gen.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        if itr >= self.configs.sampling_stop_iter and itr % self.configs.delay_interval == 0:\n",
    "            self.scheduler.step()\n",
    "            print('LR decay to:%.8f', self.optimizer.param_groups[0]['lr'])\n",
    "            \n",
    "        return next_frames, loss_d.item(), loss_gen.item()\n",
    "\n",
    "    def test(self, data, mask):\n",
    "        frames = data\n",
    "        self.network.eval()\n",
    "        frames_tensor = torch.FloatTensor(frames).to(self.configs.device)\n",
    "        mask_tensor = torch.FloatTensor(mask).to(self.configs.device)\n",
    "        next_frames = self.network(frames_tensor, mask_tensor)\n",
    "        return next_frames.detach().cpu().numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1602.514317,
   "end_time": "2022-06-20T07:47:25.608781",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-06-20T07:20:43.094464",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1d50972544d64c528e2e1520e3c81e22": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "265d9c3708e14b1daf7d5bcd36faac50": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "2a29da72c49a4b439d56344c7848355a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3141e9a3a2e24f3d943e5515c27e1fef": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "462c4a445ce44f0db18b3e546dd29ffb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_99b8af3ac8fa482d9265826f96d9b2d1",
        "IPY_MODEL_7920b39ff3a44b30a464e13df7342901",
        "IPY_MODEL_b3188f3627f347cf8de5c74ccc8a3bbf"
       ],
       "layout": "IPY_MODEL_9bd5cacd874e4359a0091bf363998e5d"
      }
     },
     "7920b39ff3a44b30a464e13df7342901": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_97dc545228ac4be7ba0fc866c5d5465f",
       "max": 244408911,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_dc3a695ff1a44937a71dd8804d289393",
       "value": 244408911
      }
     },
     "97dc545228ac4be7ba0fc866c5d5465f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "99b8af3ac8fa482d9265826f96d9b2d1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3141e9a3a2e24f3d943e5515c27e1fef",
       "placeholder": "​",
       "style": "IPY_MODEL_265d9c3708e14b1daf7d5bcd36faac50",
       "value": "100%"
      }
     },
     "9bd5cacd874e4359a0091bf363998e5d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b3188f3627f347cf8de5c74ccc8a3bbf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2a29da72c49a4b439d56344c7848355a",
       "placeholder": "​",
       "style": "IPY_MODEL_1d50972544d64c528e2e1520e3c81e22",
       "value": " 233M/233M [00:01&lt;00:00, 232MB/s]"
      }
     },
     "dc3a695ff1a44937a71dd8804d289393": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
